{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import KFold\n",
    "import re\n",
    "import nltk as nl\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('shuffled_movie_data.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pronouns = ['i','me','my','mine','you','your','yours','we','us','our','ours','myself','yourself','no']\n",
    "ex = '!'\n",
    "stop = stopwords.words('english')\n",
    "porter = PorterStemmer()\n",
    "stopWords = [n for n in stop if n not in pronouns and n not in ex]\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    text = re.sub('\\.', ' ', text)\n",
    "    #text = re.sub(':', ' : ', text)\n",
    "    emoticons = '(?::|;|=)(?:-)?(?:\\)|\\(|D|P)'\n",
    "    #emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    #exclamation = re.findall('(!)',text.lower())\n",
    "    text = re.sub('[\\W]+' + emoticons + ']', ' ', text.lower()) \n",
    "    text = [w for w in text.split() if w not in stopWords]\n",
    "    tokenized = [porter.stem(w) for w in text]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decked', ':)', 'bad']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('decked... :) bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hi for all the people who have seen this wonde...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I recently bought the DVD, forgetting just how...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0\n",
       "3  hi for all the people who have seen this wonde...          1\n",
       "4  I recently bought the DVD, forgetting just how...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive-words: Is a file that contain positive words\n",
    "\n",
    "negative-words: Is a file that contain negative words\n",
    "\n",
    "positive-emoticons: Is a file that contain positive emoticons\n",
    "\n",
    "negative-emoticons: Is a file that contain negative emoticons\n",
    "\n",
    "pronouns-words: Is a file that contain first and second pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePositive = open('lexicon/positive-words.txt', encoding = \"ISO-8859-1\")\n",
    "linesPositive = filePositive.read().split()\n",
    "filePositive.close()\n",
    "\n",
    "fileNegative = open('lexicon/negative-words.txt', encoding = \"ISO-8859-1\")\n",
    "linesNegative = fileNegative.read().split()\n",
    "fileNegative.close()\n",
    "\n",
    "fileEmoPositive = open('lexicon/positive-emoticons.txt', encoding = \"ISO-8859-1\")\n",
    "linesEmoPositive = fileEmoPositive.read().split()\n",
    "fileEmoPositive.close()\n",
    "\n",
    "fileEmoNegative = open('lexicon/negative-emoticons.txt', encoding = \"ISO-8859-1\")\n",
    "linesEmoNegative = fileEmoNegative.read().split()\n",
    "fileEmoNegative.close()\n",
    "\n",
    "filePronouns = open('lexicon/pronouns-words.txt', encoding = \"ISO-8859-1\")\n",
    "linesPronouns = filePronouns.read().split()\n",
    "filePronouns.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Create new Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colums\n",
    "\n",
    "positiveWords: Number Positive words in a review \n",
    "\n",
    "negativeWords: Number of Negative words in a review \n",
    "\n",
    "positiveEmoticons: Number Positive Emoticons in a review \n",
    "\n",
    "negativeEmoticons: Number of Negative Emoticons in a review \n",
    "\n",
    "pronouns: Number of first and second person pronouns in a review\n",
    "\n",
    "logTotalWords: log of total number of words in a review \n",
    "\n",
    "setiment: True value of sentiment of a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewList = []\n",
    "wordList = []\n",
    "matrix = pd.DataFrame(columns=['positiveWords','negativeWords','positiveEmoticons','negativeEmoticons','pronouns','logTotalWords','sentiment'])\n",
    "countRows = 0\n",
    "countFreq = 0\n",
    "\n",
    "for text in data.loc[:,'review']:\n",
    "    countColumns=0\n",
    "    #matrix[countRows][countColumns] = countRows\n",
    "    #countColumns+=1\n",
    "    wordList = tokenizer(text)\n",
    "    reviewList.append(wordList)\n",
    "    positiveWords = 0\n",
    "    negativeWord = 0\n",
    "    positiveEmoticons = 0\n",
    "    negativeEmoticons = 0\n",
    "    pronouns = 0\n",
    "    exclamation = 0 \n",
    "    noWord = 0 \n",
    "    totalWords = 0\n",
    "    for word in wordList:\n",
    "        if word in linesPositive:\n",
    "            positiveWords+=1\n",
    "        if word in linesNegative:\n",
    "            negativeWord+=1\n",
    "        if word in linesEmoPositive:\n",
    "            positiveEmoticons+=1\n",
    "        if word in linesEmoNegative:\n",
    "            negativeEmoticons+=1 \n",
    "        if word in linesPronouns:\n",
    "            pronouns+=1\n",
    "        totalWords+=1\n",
    "    logTotalWords = np.log(totalWords)\n",
    "    row = [int(positiveWords),int(negativeWord),int(positiveEmoticons),int(negativeEmoticons),int(pronouns),logTotalWords,data.loc[countRows,'sentiment']]\n",
    "    matrix.loc[countRows] = row\n",
    "    if (countRows % 5000 == 0) or (countRows == 0):\n",
    "        print(\"charging: \",countRows/500,\"%\")  \n",
    "    countRows+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"newMatrix.csv\", matrix, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read matrix from the File \"newMatrix.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positiveWords</th>\n",
       "      <th>negativeWords</th>\n",
       "      <th>positiveEmoticons</th>\n",
       "      <th>negativeEmoticons</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>logTotalWords</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   positiveWords  negativeWords  positiveEmoticons  negativeEmoticons  \\\n",
       "0            7.0           13.0                0.0                0.0   \n",
       "1           12.0            9.0                0.0                0.0   \n",
       "2           11.0           14.0                0.0                0.0   \n",
       "3            4.0            0.0                0.0                0.0   \n",
       "4            3.0            2.0                0.0                0.0   \n",
       "\n",
       "   pronouns  logTotalWords  sentiment  \n",
       "0       1.0            4.9        1.0  \n",
       "1      12.0            4.9        0.0  \n",
       "2       6.0            5.1        0.0  \n",
       "3       7.0            3.8        1.0  \n",
       "4       3.0            4.2        0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read from file \"newMatrix.csv\"\n",
    "matrix = pd.read_csv('newMatrix.csv')\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix of Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positiveWords</th>\n",
       "      <th>negativeWords</th>\n",
       "      <th>positiveEmoticons</th>\n",
       "      <th>negativeEmoticons</th>\n",
       "      <th>pronouns</th>\n",
       "      <th>logTotalWords</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>positiveWords</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.535596</td>\n",
       "      <td>0.011673</td>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.362127</td>\n",
       "      <td>0.729543</td>\n",
       "      <td>0.228444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negativeWords</th>\n",
       "      <td>0.535596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>0.335587</td>\n",
       "      <td>0.725455</td>\n",
       "      <td>0.217318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positiveEmoticons</th>\n",
       "      <td>0.011673</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>0.035927</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.032023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negativeEmoticons</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>0.017779</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.015980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pronouns</th>\n",
       "      <td>0.362127</td>\n",
       "      <td>0.335587</td>\n",
       "      <td>0.035927</td>\n",
       "      <td>0.005792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.476654</td>\n",
       "      <td>0.029281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logTotalWords</th>\n",
       "      <td>0.729543</td>\n",
       "      <td>0.725455</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.476654</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <td>0.228444</td>\n",
       "      <td>0.217318</td>\n",
       "      <td>0.032023</td>\n",
       "      <td>0.015980</td>\n",
       "      <td>0.029281</td>\n",
       "      <td>0.004701</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   positiveWords  negativeWords  positiveEmoticons  \\\n",
       "positiveWords           1.000000       0.535596           0.011673   \n",
       "negativeWords           0.535596       1.000000           0.024823   \n",
       "positiveEmoticons       0.011673       0.024823           1.000000   \n",
       "negativeEmoticons       0.010060       0.007532           0.017779   \n",
       "pronouns                0.362127       0.335587           0.035927   \n",
       "logTotalWords           0.729543       0.725455           0.003645   \n",
       "sentiment               0.228444       0.217318           0.032023   \n",
       "\n",
       "                   negativeEmoticons  pronouns  logTotalWords  sentiment  \n",
       "positiveWords               0.010060  0.362127       0.729543   0.228444  \n",
       "negativeWords               0.007532  0.335587       0.725455   0.217318  \n",
       "positiveEmoticons           0.017779  0.035927       0.003645   0.032023  \n",
       "negativeEmoticons           1.000000  0.005792       0.006000   0.015980  \n",
       "pronouns                    0.005792  1.000000       0.476654   0.029281  \n",
       "logTotalWords               0.006000  0.476654       1.000000   0.004701  \n",
       "sentiment                   0.015980  0.029281       0.004701   1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat = matrix.corr().abs()\n",
    "corrmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.insert(0, \"theta\", 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40001, 8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = matrix.loc[0:40000,:]\n",
    "test = matrix.loc[40000:50000,:]\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = train.values\n",
    "testData = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5,  7. , 13. ,  0. ,  0. ,  1. ,  4.9,  1. ],\n",
       "       [ 0.5, 12. ,  9. ,  0. ,  0. , 12. ,  4.9,  0. ],\n",
       "       [ 0.5, 11. , 14. ,  0. ,  0. ,  6. ,  5.1,  0. ],\n",
       "       [ 0.5,  4. ,  0. ,  0. ,  0. ,  7. ,  3.8,  1. ],\n",
       "       [ 0.5,  3. ,  2. ,  0. ,  0. ,  3. ,  4.2,  0. ],\n",
       "       [ 0.5,  9. ,  2. ,  0. ,  0. ,  6. ,  4.3,  1. ],\n",
       "       [ 0.5, 11. ,  3. ,  0. ,  0. ,  5. ,  5.2,  1. ],\n",
       "       [ 0.5,  3. ,  2. ,  0. ,  0. ,  1. ,  4.3,  1. ],\n",
       "       [ 0.5,  5. ,  2. ,  0. ,  0. ,  3. ,  4.2,  1. ],\n",
       "       [ 0.5,  9. ,  4. ,  0. ,  0. ,  0. ,  4.4,  1. ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. Implementation Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(M):\n",
    "    for i in range(0,10000):\n",
    "        M[i] = 1 / (1 + math.exp(-M[i]))\n",
    "    return M "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. Implementation Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define My Linear Regression \n",
    "def MyLinearRegression(pTrain,pYTrain,pTest,pYTest,cross):\n",
    "    alfa = np.power(10.0,-6.0)\n",
    "    lamba = np.power(10.0,-8.0)\n",
    "    parameters = np.empty((7,1))\n",
    "    parameters[:] = 0.1 * np.random.rand() \n",
    "    count = 0\n",
    "    cycle = 5000\n",
    "    max = 0\n",
    "    while(count < cycle):\n",
    "        cost = 0\n",
    "        for i in range(1,4):\n",
    "            currentTrain = pTrain[10000*(i-1):(i*10000),:]\n",
    "            currentYTrain = pYTrain[10000*(i-1):(i*10000)]\n",
    "            h = np.matmul(currentTrain,parameters)\n",
    "            y = sigmoid(h)\n",
    "            error = y - currentYTrain\n",
    "            derivate = np.matmul(error.T,currentTrain)\n",
    "            parameters = parameters - (alfa *derivate.T) - (lamba * parameters)\n",
    "            loss = -1*np.mean(np.multiply(currentYTrain,np.log(y)) + np.multiply((1-currentYTrain),np.log(1-y)))\n",
    "        count= count + 1\n",
    "        if (count % 1000 == 0) or (count == 1):  \n",
    "            hTest = np.matmul(pTest,parameters)\n",
    "            hTest = sigmoid(hTest)\n",
    "            print(\"----Cross validation \",cross,\" ----\")\n",
    "            print(\"----Epoch \",count,\" ----\")\n",
    "            print(\"loss: \",loss)\n",
    "            print(\"accuracy: \",accuracy_score(pYTest, hTest.round()))\n",
    "        alfa = alfa + np.power(10.0,-15.0)\n",
    "    if cross == 3:\n",
    "        global mrlWeight\n",
    "        mrlWeight = parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40001, 8)\n",
      "------------- My Logistics Regression ---------\n",
      "----Cross validation  1  ----\n",
      "----Epoch  1  ----\n",
      "loss:  0.6850454588554895\n",
      "accuracy:  0.5924407559244076\n",
      "----Cross validation  1  ----\n",
      "----Epoch  1000  ----\n",
      "loss:  0.5584875067336665\n",
      "accuracy:  0.7207279272072793\n",
      "----Cross validation  1  ----\n",
      "----Epoch  2000  ----\n",
      "loss:  0.5584760434692756\n",
      "accuracy:  0.7208279172082792\n",
      "----Cross validation  1  ----\n",
      "----Epoch  3000  ----\n",
      "loss:  0.5584653781933328\n",
      "accuracy:  0.7207279272072793\n",
      "----Cross validation  1  ----\n",
      "----Epoch  4000  ----\n",
      "loss:  0.5584554450482067\n",
      "accuracy:  0.7206279372062794\n",
      "----Cross validation  1  ----\n",
      "----Epoch  5000  ----\n",
      "loss:  0.558446184097401\n",
      "accuracy:  0.7206279372062794\n",
      "------------- My Logistics Regression ---------\n",
      "----Cross validation  2  ----\n",
      "----Epoch  1  ----\n",
      "loss:  0.772898366621062\n",
      "accuracy:  0.5145\n",
      "----Cross validation  2  ----\n",
      "----Epoch  1000  ----\n",
      "loss:  0.5583689934652375\n",
      "accuracy:  0.7326\n",
      "----Cross validation  2  ----\n",
      "----Epoch  2000  ----\n",
      "loss:  0.5583532594844329\n",
      "accuracy:  0.7326\n",
      "----Cross validation  2  ----\n",
      "----Epoch  3000  ----\n",
      "loss:  0.5583389383046455\n",
      "accuracy:  0.7325\n",
      "----Cross validation  2  ----\n",
      "----Epoch  4000  ----\n",
      "loss:  0.5583258863190107\n",
      "accuracy:  0.7324\n",
      "----Cross validation  2  ----\n",
      "----Epoch  5000  ----\n",
      "loss:  0.5583139753052745\n",
      "accuracy:  0.7323\n",
      "------------- My Logistics Regression ---------\n",
      "----Cross validation  3  ----\n",
      "----Epoch  1  ----\n",
      "loss:  0.779292894666742\n",
      "accuracy:  0.4998\n",
      "----Cross validation  3  ----\n",
      "----Epoch  1000  ----\n",
      "loss:  0.5583791476403609\n",
      "accuracy:  0.7346\n",
      "----Cross validation  3  ----\n",
      "----Epoch  2000  ----\n",
      "loss:  0.5583683286232485\n",
      "accuracy:  0.7346\n",
      "----Cross validation  3  ----\n",
      "----Epoch  3000  ----\n",
      "loss:  0.5583582045932364\n",
      "accuracy:  0.7347\n",
      "----Cross validation  3  ----\n",
      "----Epoch  4000  ----\n",
      "loss:  0.5583487204315594\n",
      "accuracy:  0.7348\n",
      "----Cross validation  3  ----\n",
      "----Epoch  5000  ----\n",
      "loss:  0.5583398258273928\n",
      "accuracy:  0.7348\n",
      "------------- My Logistics Regression ---------\n",
      "----Cross validation  4  ----\n",
      "----Epoch  1  ----\n",
      "loss:  0.74370047692441\n",
      "accuracy:  0.523\n",
      "----Cross validation  4  ----\n",
      "----Epoch  1000  ----\n",
      "loss:  0.5561798045548851\n",
      "accuracy:  0.7315\n",
      "----Cross validation  4  ----\n",
      "----Epoch  2000  ----\n",
      "loss:  0.5561657298610905\n",
      "accuracy:  0.7314\n",
      "----Cross validation  4  ----\n",
      "----Epoch  3000  ----\n",
      "loss:  0.5561527037820302\n",
      "accuracy:  0.7314\n",
      "----Cross validation  4  ----\n",
      "----Epoch  4000  ----\n",
      "loss:  0.5561406355473506\n",
      "accuracy:  0.7315\n",
      "----Cross validation  4  ----\n",
      "----Epoch  5000  ----\n",
      "loss:  0.5561294432397177\n",
      "accuracy:  0.7315\n"
     ]
    }
   ],
   "source": [
    "### Cross validation \n",
    "kFolds = KFold(n_splits=4)\n",
    "countCross = 1\n",
    "print(trainData.shape)\n",
    "for train, test in kFolds.split(trainData):\n",
    "    trainD = trainData[train,0:7]\n",
    "    testD = trainData[test,0:7]\n",
    "    yTrain = trainData[train,7:8]\n",
    "    yTest = trainData[test,7:8]\n",
    "    print(\"------------- My Logistics Regression ---------\")\n",
    "    MyLinearRegression(trainD,yTrain,testD,yTest,countCross)\n",
    "    countCross = countCross + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest = testData[:,0:7]\n",
    "yTest = testData[:,7:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrlWeight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"parameters.csv\", mrlWeight, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7274\n"
     ]
    }
   ],
   "source": [
    "predictTest = np.matmul(xTest,mrlWeight)\n",
    "predictTest = sigmoid(predictTest)\n",
    "print(\"accuracy: \",accuracy_score(yTest, predictTest.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
